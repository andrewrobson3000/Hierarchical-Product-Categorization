{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload into Jupiter the excel 'product-cat-dataset.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import ngrams\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#import data\n",
    "df = pd.read_csv('product-cat-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I make a copy of the df and drop null values\n",
    "df2 = df.copy()\n",
    "df2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Description   Level_1 Level_2  \\\n",
      "0      gerb cap help keep littl on head cov warm day ...  09BF5150   C7E19   \n",
      "1      newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6   \n",
      "2      tut ballet anym leap foxy fash ruffl tul toddl...  09BF5150   C7E19   \n",
      "3      newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6   \n",
      "4      easy keep feel warm cozy inf toddl girl hoody ...  2CEC27F1   ADAD6   \n",
      "...                                                  ...       ...     ...   \n",
      "10644  term 10 issu on year subscriptionyo sav 75 cov...  90A8B052   C719A   \n",
      "10645  term 12 issu on year subscriptionyo sav 86 cov...  90A8B052   C719A   \n",
      "10646  term 9 issu on year subscriptionyo sav 64 cov ...  90A8B052   C719A   \n",
      "10647  term 26 issu on year subscriptionyo sav 54 cov...  90A8B052   C719A   \n",
      "10648  term 12 issu on year subscriptionyo sav 60 cov...  90A8B052   C719A   \n",
      "\n",
      "      Level_3  \n",
      "0        D06E  \n",
      "1        98CF  \n",
      "2        D06E  \n",
      "3        98CF  \n",
      "4        98CF  \n",
      "...       ...  \n",
      "10644    A0E2  \n",
      "10645    A0E2  \n",
      "10646    A0E2  \n",
      "10647    A0E2  \n",
      "10648    A0E2  \n",
      "\n",
      "[10629 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Counts the occurrences of each unique value in the \"Level_2\" column and creates a new column with these counts\n",
    "counts_col2 = df2.groupby(\"Level_2\")[\"Level_2\"].transform(len)\n",
    "\n",
    "# Creates a boolean mask indicating whether the count of occurrences for each \"Level_2\" value is greater than 10\n",
    "mask = (counts_col2 > 10)\n",
    "\n",
    "# Filters the DataFrame df2 based on the boolean mask, keeping only the rows where the count of occurrences for the corresponding \"Level_2\" value is greater than 10\n",
    "df3 = df2[mask]\n",
    "\n",
    "# Prints the resulting DataFrame df3, which contains only the rows where the count of occurrences for the corresponding \"Level_2\" value is greater than 10\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Description   Level_1 Level_2  \\\n",
      "0      gerb cap help keep littl on head cov warm day ...  09BF5150   C7E19   \n",
      "1      newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6   \n",
      "2      tut ballet anym leap foxy fash ruffl tul toddl...  09BF5150   C7E19   \n",
      "3      newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6   \n",
      "4      easy keep feel warm cozy inf toddl girl hoody ...  2CEC27F1   ADAD6   \n",
      "...                                                  ...       ...     ...   \n",
      "10644  term 10 issu on year subscriptionyo sav 75 cov...  90A8B052   C719A   \n",
      "10645  term 12 issu on year subscriptionyo sav 86 cov...  90A8B052   C719A   \n",
      "10646  term 9 issu on year subscriptionyo sav 64 cov ...  90A8B052   C719A   \n",
      "10647  term 26 issu on year subscriptionyo sav 54 cov...  90A8B052   C719A   \n",
      "10648  term 12 issu on year subscriptionyo sav 60 cov...  90A8B052   C719A   \n",
      "\n",
      "      Level_3  \n",
      "0        D06E  \n",
      "1        98CF  \n",
      "2        D06E  \n",
      "3        98CF  \n",
      "4        98CF  \n",
      "...       ...  \n",
      "10644    A0E2  \n",
      "10645    A0E2  \n",
      "10646    A0E2  \n",
      "10647    A0E2  \n",
      "10648    A0E2  \n",
      "\n",
      "[10627 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculates the number of occurrences of each unique value in the \"Level_3\" column and creates a new column with these counts\n",
    "counts_col2 = df2.groupby(\"Level_3\")[\"Level_3\"].transform(len)\n",
    "\n",
    "# Creates a boolean mask indicating whether the count of occurrences for each \"Level_3\" value is greater than 10\n",
    "mask = (counts_col2 > 10)\n",
    "\n",
    "# Filters the DataFrame df2 based on the boolean mask, keeping only the rows where the count of occurrences for the corresponding \"Level_3\" value is greater than 10\n",
    "df3 = df2[mask]\n",
    "\n",
    "# Prints the resulting DataFrame df3, which contains only the rows where the count of occurrences for the corresponding \"Level_3\" value is greater than 10\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [(gerb,), (cap,), (help,), (keep,), (littl,), ...\n",
      "1        [(newborn,), (inf,), (toddl,), (boy,), (hoodi,...\n",
      "2        [(tut,), (ballet,), (anym,), (leap,), (foxi,),...\n",
      "3        [(newborn,), (inf,), (toddl,), (boy,), (hoodi,...\n",
      "4        [(easi,), (keep,), (feel,), (warm,), (cozi,), ...\n",
      "                               ...                        \n",
      "10644    [(term,), (10,), (issu,), (on,), (year,), (sub...\n",
      "10645    [(term,), (12,), (issu,), (on,), (year,), (sub...\n",
      "10646    [(term,), (9,), (issu,), (on,), (year,), (subs...\n",
      "10647    [(term,), (26,), (issu,), (on,), (year,), (sub...\n",
      "10648    [(term,), (12,), (issu,), (on,), (year,), (sub...\n",
      "Name: Description, Length: 10627, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extracts the 'Description' column from DataFrame df3\n",
    "text = df3[\"Description\"]\n",
    "\n",
    "# Defines a function named process_text that takes a text input and an integer n\n",
    "def process_text(text1, n):\n",
    "    \n",
    "    # Converts all text to lowercase\n",
    "    text2 = text1.str.lower()\n",
    "   \n",
    "    # Replaces punctuation marks with empty space using regular expressions\n",
    "    text3 = text2.str.replace(r'[\\\\,.!_:/+%&-]', '', regex=True)\n",
    "    \n",
    "    # Splits the text into individual words\n",
    "    text4 = text3.str.split(\" \")\n",
    "    \n",
    "    # Applies the PorterStemmer (optional) to reduce words to their root form\n",
    "    ps = PorterStemmer()\n",
    "    text5 = text4.apply(lambda x: [ps.stem(y) for y in x])\n",
    "    \n",
    "    # Applies n-gram tokenization to the text and converts it to a list\n",
    "    tokenized = text5.apply(lambda x: list(ngrams(x, n)))\n",
    "    \n",
    "    # Returns the tokenized text\n",
    "    return tokenized\n",
    "\n",
    "# Calls the process_text function with the 'Description' column of DataFrame df3 and n=1\n",
    "result = process_text(df3['Description'], 1)\n",
    "\n",
    "# Prints the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the CountVectorizer with a custom tokenizer function and set lowercase to False\n",
    "# CountVectorizer converts a collection of text documents to a matrix of token counts\n",
    "cv = CountVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "# TfidfVectorizer converts a collection of raw documents to a matrix of TF-IDF features\n",
    "tfv = TfidfVectorizer()\n",
    "\n",
    "# Initialize the TfidfTransformer\n",
    "# TfidfTransformer transforms a count matrix to a normalized TF or TF-IDF representation\n",
    "tft = TfidfTransformer(smooth_idf=True)\n",
    "\n",
    "# Apply the CountVectorizer to transform the result (tokenized text) into a bag of words (bow)\n",
    "bow = cv.fit_transform(result)\n",
    "\n",
    "# Apply the TfidfTransformer to convert the bag of words (bow) into TF-IDF representation (tfidf)\n",
    "tfidf = tft.fit_transform(bow)\n",
    "\n",
    "# Convert the resulting TF-IDF matrix into a dense DataFrame\n",
    "# This step is to make it easier to visualize, as the TF-IDF matrix is typically sparse\n",
    "text_tfidf = pd.DataFrame(tfidf.toarray()).astype(dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting columns 'Level_1', 'Level_2', and 'Level_3' from the DataFrame df\n",
    "df3 = df[['Level_1', 'Level_2', 'Level_3']]\n",
    "\n",
    "# Joining the DataFrame text_tfidf (containing TF-IDF representation of text) with df3 on the index\n",
    "# This step is not necessary , but it's being done here to combine the dataframes\n",
    "table = text_tfidf.join(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "train, test =train_test_split(table, test_size=0.2, random_state=888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the 'Level_1', 'Level_2', and 'Level_3' columns from the DataFrame 'train'\n",
    "# Converting them to strings using the astype method\n",
    "# This step is performed to ensure that the values are treated as strings\n",
    "class1 = train['Level_1'].astype(str)\n",
    "class2 = train['Level_2'].astype(str)\n",
    "class3 = train['Level_3'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model for level 1\n",
    "tree=DecisionTreeClassifier()\n",
    "\n",
    "#fit the model on the level 1 clasification using 'Description' col data\n",
    "datavector=train.iloc[:,0:16252]\n",
    "tree.fit(datavector, class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for level 1\n",
    "with open('Level1.pk', 'wb') as classes:\n",
    "    pickle.dump(tree,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save models for level 2 in for loop\n",
    "\n",
    "for i in np.unique(class1):\n",
    "    class1_indices=list(class1[class1==i].index)\n",
    "    all_train=train.loc[class1_indices,:]\n",
    "    data_train=all_train.iloc[:,0:16252]\n",
    "    class2_labels=class2.loc[class1_indices]\n",
    "    \n",
    "    tree=DecisionTreeClassifier()\n",
    "    tree.fit(data_train, class2_labels)\n",
    "   \n",
    "    with open(\"Level2_\"+i+\".pk\", 'wb') as classes:\n",
    "        pickle.dump(tree,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save models for level 3\n",
    "\n",
    "for i in np.unique(class2):\n",
    "    class2_indices=list(class2[class2==i].index)\n",
    "    all_train2=train.loc[class2_indices,:]\n",
    "    data_train2=all_train2.iloc[:,0:16252]\n",
    "    class3_labels=class3.loc[class2_indices]\n",
    "    \n",
    "    tree=DecisionTreeClassifier()\n",
    "    tree.fit(data_train2, class3_labels)\n",
    "   \n",
    "    with open(\"Level3_\"+i+\".pk\", 'wb') as classes:\n",
    "        pickle.dump(tree,classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16245</th>\n",
       "      <th>16246</th>\n",
       "      <th>16247</th>\n",
       "      <th>16248</th>\n",
       "      <th>16249</th>\n",
       "      <th>16250</th>\n",
       "      <th>16251</th>\n",
       "      <th>Level_1</th>\n",
       "      <th>Level_2</th>\n",
       "      <th>Level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3E1E0D78</td>\n",
       "      <td>9D9EE</td>\n",
       "      <td>05A0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9646</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3E1E0D78</td>\n",
       "      <td>9D9EE</td>\n",
       "      <td>05A0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>09BF5150</td>\n",
       "      <td>C7E19</td>\n",
       "      <td>D06E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4471</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EFEF723B</td>\n",
       "      <td>CB803</td>\n",
       "      <td>627D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69286F45</td>\n",
       "      <td>2D5A3</td>\n",
       "      <td>28A7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  16245  16246  \\\n",
       "9286  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "9646  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "2195  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "4471  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "1954  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "\n",
       "      16247  16248  16249  16250  16251   Level_1  Level_2  Level_3  \n",
       "9286    0.0    0.0    0.0    0.0    0.0  3E1E0D78    9D9EE     05A0  \n",
       "9646    0.0    0.0    0.0    0.0    0.0  3E1E0D78    9D9EE     05A0  \n",
       "2195    0.0    0.0    0.0    0.0    0.0  09BF5150    C7E19     D06E  \n",
       "4471    0.0    0.0    0.0    0.0    0.0  EFEF723B    CB803     627D  \n",
       "1954    0.0    0.0    0.0    0.0    0.0  69286F45    2D5A3     28A7  \n",
       "\n",
       "[5 rows x 16255 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the 'Level_1', 'Level_2', and 'Level_3' columns from the DataFrame 'test'\n",
    "# Converting them to strings using the astype method\n",
    "# This step is performed to ensure that the values are treated as strings\n",
    "testclass1 = test['Level_1'].astype(str)\n",
    "testclass2 = test['Level_2'].astype(str)\n",
    "testclass3 = test['Level_3'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3E1E0D78', '3E1E0D78', '09BF5150', ..., 'B092BA29', '96F95EEC',\n",
       "       '69286F45'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the features from the test data to be used for prediction\n",
    "data_test = test.iloc[:, 0:16252]\n",
    "\n",
    "# Loading the saved model for predicting Level 1\n",
    "with open('Level1.pk', 'rb') as tree:\n",
    "    model = pickle.load(tree)\n",
    "\n",
    "# Using the loaded model to predict Level 1 for the test data\n",
    "level1_pred = model.predict(data_test)\n",
    "\n",
    "# Displaying the predictions for Level 1\n",
    "level1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CB803', 'CB803', 'CB803', ..., '02FA0', '02FA0', '02FA0'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looping through unique values in testclass1 (Level 1 classes)\n",
    "for i in np.unique(testclass1):\n",
    "    \n",
    "    # Loading the saved model for predicting Level 2 based on Level 1 class i\n",
    "    with open('Level2_'+i+'.pk', 'rb') as tree:\n",
    "        model = pickle.load(tree)\n",
    "    \n",
    "    # Finding the indices of rows in test data belonging to Level 1 class i\n",
    "    class1_indices = list(testclass1[testclass1 == i].index)\n",
    "    \n",
    "    # Selecting all rows from the test data that belong to Level 1 class i\n",
    "    all_test1 = test.loc[class1_indices, :]\n",
    "    \n",
    "    # Selecting features from the test data to be used for prediction\n",
    "    data_test1 = all_test1.iloc[:, 0:16252]\n",
    "    \n",
    "    # Using the loaded model to predict Level 2 for the selected test data\n",
    "    level2_pred = model.predict(data_test)\n",
    "\n",
    "# Displaying the predictions for Level 2\n",
    "level2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2126,)\n"
     ]
    }
   ],
   "source": [
    "# Looping through unique values in testclass2 (Level 2 classes)\n",
    "for i in np.unique(testclass2):\n",
    "    \n",
    "    # Loading the saved model for predicting Level 3 based on Level 2 class i\n",
    "    with open('Level3_'+i+'.pk', 'rb') as tree:\n",
    "        model = pickle.load(tree)\n",
    "    \n",
    "    # Finding the indices of rows in test data belonging to Level 2 class i\n",
    "    class2_indices = list(testclass2[testclass2 == i].index)\n",
    "    \n",
    "    # Selecting all rows from the test data that belong to Level 2 class i\n",
    "    all_test2 = test.loc[class2_indices, :]\n",
    "    \n",
    "    # Selecting features from the test data to be used for prediction\n",
    "    data_test2 = all_test2.iloc[:, 0:16252]\n",
    "    \n",
    "    # Using the loaded model to predict Level 3 for the selected test data\n",
    "    level3_pred = model.predict(data_test)\n",
    "\n",
    "# Printing the shape of level3_pred\n",
    "print(level3_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Level1_Pred Level2_Pred Level3_Pred\n",
      "0    3E1E0D78       CB803        7288\n",
      "1    3E1E0D78       CB803        7288\n",
      "2    09BF5150       CB803        7288\n",
      "3    EFEF723B       CB803        7288\n",
      "4    69286F45       CB803        7288\n"
     ]
    }
   ],
   "source": [
    "# Converting predictions to numpy arrays if they're not already\n",
    "level1_pred = np.array(level1_pred)\n",
    "level2_pred = np.array(level2_pred)\n",
    "level3_pred = np.array(level3_pred)\n",
    "\n",
    "# Creating a DataFrame containing the predictions for each level\n",
    "results = pd.DataFrame({\n",
    "    'Level1_Pred': level1_pred,\n",
    "    'Level2_Pred': level2_pred,\n",
    "    'Level3_Pred': level3_pred\n",
    "})\n",
    "\n",
    "# Displaying the first few rows of the results DataFrame\n",
    "print(results.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Accuracy on each level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Level 1: 0.7954\n",
      "Accuracy for Level 2: 0.0536\n",
      "Accuracy for Level 3: 0.0094\n"
     ]
    }
   ],
   "source": [
    "# Level 1 accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming testclass1, testclass2, testclass3 are the actual labels for the test set\n",
    "# And level1_pred, level2_pred, level3_pred are the predictions from your models\n",
    "\n",
    "# Compute accuracy for each level\n",
    "accuracy_level1 = accuracy_score(testclass1, level1_pred)\n",
    "accuracy_level2 = accuracy_score(testclass2, level2_pred)\n",
    "accuracy_level3 = accuracy_score(testclass3, level3_pred)\n",
    "\n",
    "# Print out the accuracy for each level\n",
    "print(f\"Accuracy for Level 1: {accuracy_level1:.4f}\")\n",
    "print(f\"Accuracy for Level 2: {accuracy_level2:.4f}\")\n",
    "print(f\"Accuracy for Level 3: {accuracy_level3:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
